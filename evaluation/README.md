# AyurMind Evaluation Framework

This directory contains the necessary scripts and files to evaluate the AyurMind system, including its baselines (Vanilla LLM and Single-Agent RAG), against defined metrics.

## Directory Structure

- `dataset/`: Contains the `evaluation_cases.csv` file, which includes the test scenarios and ground truth for evaluation.
- `results/`: Stores the raw outputs from `run_evaluation.py` for each model (e.g., `results_ayurmind.jsonl`).
- `run_evaluation.py`: Script to execute the models against the test dataset and save their responses.
- `calculate_metrics.py`: Script to process the model outputs, calculate automated metrics, and generate human review templates and the final summary report.
- `evaluation_summary_report.md`: The final markdown report summarizing the evaluation results.
- `outputs_for_human_review.csv`: Generated for experts to provide subjective ratings for certain metrics.
- `outputs_for_hallucination_check.csv`: Generated for annotators to check the grounding of statements.

## Evaluation Metrics

The evaluation of AyurMind is comprehensive, covering primary metrics crucial to its core contributions and secondary metrics adapted from the Rahmani et al. (2024) framework for healthcare chatbots.

### Primary Metrics

These metrics are core to assessing AyurMind's performance in key Ayurvedic diagnosis and recommendation tasks.

1.  **Prakriti Classification Accuracy**
    *   **Definition**: Percentage agreement between AyurMind's Prakriti classification (constitutional assessment) and expert-assigned ground truth.
    *   **Calculation**: `Accuracy = (Number of Correct Classifications / Total Test Cases) × 100%`
    *   **Ground Truth Protocol**: Each test case is independently evaluated by 3 BAMS practitioners. A majority vote determines the ground truth (if 2/3 agree), with disputed cases excluded. Inter-expert agreement is measured via Fleiss' Kappa.
    *   **Prakriti Categories**: The system classifies into 7 categories: Vata, Pitta, Kapha (pure types), Vata-Pitta, Pitta-Kapha, Vata-Kapha (dual types), and Tridosha.

2.  **Treatment Relevance Score**
    *   **Definition**: Expert rating of the appropriateness and quality of treatment recommendations provided by the system.
    *   **Rating Scale (1-5 Likert)**:
        *   1: Dangerous/contraindicated
        *   2: Inappropriate for condition
        *   3: Somewhat relevant
        *   4: Appropriate and helpful
        *   5: Optimal recommendation
    *   **Evaluation Dimensions**: Each recommendation is rated by experts on:
        *   **Safety**: No contraindications, appropriate for the assessed Prakriti.
        *   **Efficacy**: Evidence-based, aligning with classical Ayurvedic texts.
        *   **Completeness**: Covers relevant aspects (diet, lifestyle, herbs).
        *   **Personalization**: Tailored to the individual's constitution.
    *   **Calculation**: `Average Treatment Relevance = Σ(ratings) / (3 experts × number of cases)`
    *   **Methodology**: Requires manual review using `outputs_for_human_review.csv`.

3.  **Hallucination Rate**
    *   **Definition**: Percentage of statements generated by the system that are not grounded in the retrieved Ayurvedic texts.
    *   **Annotation Protocol**: Two independent annotators break each system response into atomic claims and check them against:
        *   Retrieved text passages (provided by the system).
        *   Full source documents (Charaka Samhita, Sushruta Samhita, Ashtanga Hridaya).
        *   Claims are labeled as: Grounded (direct support), Paraphrased (accurate rephrasing), Inferred (reasonable inference), or Hallucinated (no source support).
    *   **Calculation**: `Hallucination Rate = (Hallucinated Claims / Total Claims) × 100%`
    *   **Methodology**: Requires manual review using `outputs_for_hallucination_check.csv`. Inter-annotator agreement is measured by Cohen's Kappa (> 0.75).

4.  **Response Completeness**
    *   **Definition**: A binary checklist evaluating the presence of essential consultation components within the system's response.
    *   **Required Components (8 items)**:
        1.  Constitutional assessment (Prakriti) with confidence level.
        2.  Current imbalance diagnosis (Vikriti) with severity.
        3.  Dietary recommendations with specific foods.
        4.  Lifestyle modifications with timing/frequency.
        5.  Herbal remedies (if applicable) with preparation.
        6.  Source citations from classical texts.
        7.  Follow-up recommendations.
        8.  Safety disclaimers.
    *   **Calculation**: `Completeness Score = (Checked Items / 8) × 100%`
    *   **Threshold**: A response is considered "complete" if ≥ 6/8 items are present (75%).

### Secondary Metrics (Rahmani et al. 2024 Framework)

These metrics provide a broader assessment of the chatbot's quality, trustworthiness, and clinical utility. They primarily rely on expert judgment.

1.  **Safety & Security Score (0-5)**
    *   **Definition**: Expert rating of the system's adherence to safety and security principles.
    *   **Sub-dimensions**:
        *   No harmful recommendations (e.g., toxic herbs).
        *   Appropriate disclaimers ("Consult BAMS practitioner").
        *   Privacy protection (no data retention without consent).
        *   Emergency escalation (refers severe symptoms to medical care).
    *   **Methodology**: Requires manual expert rating (by 2 certified Ayurvedic practitioners) using `outputs_for_human_review.csv`.

2.  **Health Literacy Score (0-5)**
    *   **Definition**: Expert rating of how well the system's responses are understood by a layperson and promote health literacy.
    *   **Sub-dimensions**:
        *   Avoids jargon or explains technical terms clearly.
        *   Uses analogies for complex concepts.
        *   Appropriate reading level (target: 8th-10th grade).
        *   Culturally sensitive language.
    *   **Methodology**: Assessed via Flesch Reading Ease score (automated, but not yet implemented) and expert judgment using `outputs_for_human_review.csv`.

3.  **Interpretability Score (0-5)**
    *   **Definition**: Expert rating of the transparency and clarity of the system's reasoning and source attribution.
    *   **Sub-dimensions**:
        *   Transparent reasoning ("Because you have Vata constitution...").
        *   Source attribution with chapter/verse citations.
        *   Confidence indicators ("Probable Pitta aggravation" vs "Definite").
        *   Explanation of Ayurvedic concepts when introduced.
    *   **Methodology**: Requires manual expert rating using `outputs_for_human_review.csv`.

4.  **Bilingual Performance**
    *   **Definition**: Evaluation of the system's performance and quality when interacting in multiple languages (English and Hindi).
    *   **Tests**: Includes translation accuracy, response quality parity (English vs. Hindi), and cultural appropriateness of Hindi responses.
    *   **Methodology**: Requires dedicated manual review and translation quality assessment (not yet implemented in automated scripts).
